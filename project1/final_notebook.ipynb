{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Qegu5r_Fq1oI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709835796849,"user_tz":300,"elapsed":1206,"user":{"displayName":"Jerry Xiao","userId":"01620358338097358872"}},"outputId":"293fba2b-0a49-4e12-ab1c-2a4f1f437355"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Change working directory to where your .ipynb file is located\n","os.chdir('/content/drive/My Drive/CSDS 335/Project1/code')\n","# os.chdir('/content/drive/My Drive/Project1/code')"],"metadata":{"id":"Z5FL6J7ly4cR","executionInfo":{"status":"ok","timestamp":1709835814977,"user_tz":300,"elapsed":6,"user":{"displayName":"Jerry Xiao","userId":"01620358338097358872"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Import all of the models and related functions\n","from data_loading import *\n","from cv_and_eval import *\n","\n","from naive_bayes import *\n","from svm import *\n","from knn import *\n","from decisiontree import *\n","from adaboost import *"],"metadata":{"id":"2hUIeeXauWqS","executionInfo":{"status":"ok","timestamp":1709835821346,"user_tz":300,"elapsed":3459,"user":{"displayName":"Jerry Xiao","userId":"01620358338097358872"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Load the dataset\n","X2, y2 = load_dataset_2(212)\n","X1, y1 = load_dataset_1(212)"],"metadata":{"id":"pAxvdHX7u1Pw","executionInfo":{"status":"ok","timestamp":1709835821349,"user_tz":300,"elapsed":15,"user":{"displayName":"Jerry Xiao","userId":"01620358338097358872"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Naive Bayes\n","Hyperparameter: The size of training set"],"metadata":{"id":"P0OnIiD4LmhK"}},{"cell_type":"markdown","source":["### Dataset1"],"metadata":{"id":"P8n_9WYWI4za"}},{"cell_type":"code","source":["# Optimize parameters\n","print('Grid Search Results:')\n","split_prop = naive_bayes_test_params(X1, y1, [.5,.6,.7,.8,.9])\n","\n","# Split the data based on hyperparam tuning\n","split_ind = int(split_prop*len(X1))\n","X_train = X1[:split_ind]\n","y_train = y1[:split_ind]\n","\n","X_test = X1[split_ind:]\n","y_test = y1[split_ind:]\n","\n","# Train and evaluate the final model\n","model1 = NaiveBayes()\n","model1.fit(X_train, y_train)\n","y_pred = model1.predict(X_test)\n","\n","print()\n","acc, prec, rec, f1 = eval_predictions(y_test, y_pred)\n","print(\"Final Results:\")\n","print(f'Accuracy: {acc}')\n","print(f'Precision: {prec}')\n","print(f'Recall: {rec}')\n","print(f'F1 score: {f1}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xzA8e2P0E2R5","executionInfo":{"status":"ok","timestamp":1709836209538,"user_tz":300,"elapsed":599,"user":{"displayName":"Jerry Xiao","userId":"01620358338097358872"}},"outputId":"cd1de27a-91bf-4468-e855-b78fd8021c72"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Grid Search Results:\n","best split threshold: 0.5\n","best acc: 0.9404797601199402\n","best prec: 0.9421356421257482\n","best rec: 0.9026373626282187\n","best f1: 0.9179625156311394\n","\n","Final Results:\n","Accuracy: 0.9473684210526315\n","Precision: 0.9696969696959902\n","Recall: 0.8888888888880658\n","F1 score: 0.9275362318831618\n"]}]},{"cell_type":"markdown","source":["### Dataset2"],"metadata":{"id":"0gM6P8LjI7Er"}},{"cell_type":"code","execution_count":16,"metadata":{"id":"y8UF1fJBBQtk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709836209845,"user_tz":300,"elapsed":2,"user":{"displayName":"Jerry Xiao","userId":"01620358338097358872"}},"outputId":"7516bffe-f7a1-4921-bbeb-f9ea64c8e4c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Grid Search Results:\n","best split threshold: 0.6\n","best acc: 0.7327142857142857\n","best prec: 0.5891774891722166\n","best rec: 0.7016233766155413\n","best f1: 0.6338959756922076\n","\n","Final Results:\n","Accuracy: 0.6648648648648648\n","Precision: 0.5142857142849796\n","Recall: 0.562499999999121\n","F1 score: 0.537313432835019\n"]}],"source":["# Optimize parameters\n","print('Grid Search Results:')\n","split_prop = naive_bayes_test_params(X2, y2, [.5,.6,.7,.8,.9])\n","\n","# Split the data based on hyperparam tuning\n","split_ind = int(split_prop*len(X2))\n","X_train = X2[:split_ind]\n","y_train = y2[:split_ind]\n","\n","X_test = X2[split_ind:]\n","y_test = y2[split_ind:]\n","\n","# Train and evaluate the final model\n","model1 = NaiveBayes()\n","model1.fit(X_train, y_train)\n","y_pred = model1.predict(X_test)\n","\n","print()\n","acc, prec, rec, f1 = eval_predictions(y_test, y_pred)\n","print(\"Final Results:\")\n","print(f'Accuracy: {acc}')\n","print(f'Precision: {prec}')\n","print(f'Recall: {rec}')\n","print(f'F1 score: {f1}')"]},{"cell_type":"markdown","source":["# SVM\n","Hyperparameters: C(lambda) and gamma"],"metadata":{"id":"ZEufyxLjLoxv"}},{"cell_type":"markdown","source":["### Dataset1"],"metadata":{"id":"XQKdbsgoJLUW"}},{"cell_type":"code","execution_count":17,"metadata":{"id":"CMie6MxblOAC","colab":{"base_uri":"https://localhost:8080/"},"outputId":"27b1479f-6b04-453c-8959-c150db46dc35","executionInfo":{"status":"ok","timestamp":1709836600783,"user_tz":300,"elapsed":386770,"user":{"displayName":"Jerry Xiao","userId":"01620358338097358872"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Grid Search Results:\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CSDS 335/Project1/code/cv_and_eval.py:81: RuntimeWarning: invalid value encountered in scalar divide\n","  return 2 * (prec * rec) / (prec + rec)\n"]},{"output_type":"stream","name":"stdout","text":["best gamma: 0.01\n","best lambda: 0.1\n","best acc: 0.9410392364793214\n","best prec: 0.8716071428518577\n","best rec: 0.854702911462551\n","best f1: nan\n","\n","Final Results:\n","Accuracy: 0.9473684210526315\n","Precision: 0.9736842105237534\n","Recall: 0.8809523809502834\n","F1 score: 0.9249999999976874\n"]}],"source":["# Train test split\n","split_ind = int(0.8*len(X1))\n","X_train = X1[:split_ind]\n","y_train = y1[:split_ind]\n","\n","X_test = X1[split_ind:]\n","y_test = y1[split_ind:]\n","\n","# Optimize parameters using X_train\n","print('Grid Search Results:')\n","l1, g1 = SVM_test_params(X_train, y_train)\n","\n","# Train best model and evaluate\n","model1 = rbf_SVM(C = l1, gamma = g1)\n","model1.fit(X_train, y_train)\n","y_pred = model1.predict(X_test)\n","\n","print()\n","acc, prec, rec, f1 = eval_predictions(y_test, y_pred)\n","print(\"Final Results:\")\n","print(f'Accuracy: {acc}')\n","print(f'Precision: {prec}')\n","print(f'Recall: {rec}')\n","print(f'F1 score: {f1}')"]},{"cell_type":"markdown","source":["### Dataset2"],"metadata":{"id":"fiKe3bmHJNIH"}},{"cell_type":"code","execution_count":18,"metadata":{"id":"Ir-dhnisG3cM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709836856842,"user_tz":300,"elapsed":256063,"user":{"displayName":"Jerry Xiao","userId":"01620358338097358872"}},"outputId":"7354ca1a-7ca0-480a-a34a-f61eec656eba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Grid Search Results:\n","best gamma: 1.0\n","best lambda: 0.1\n","best acc: 0.7234984984984985\n","best prec: 0.63089133088466\n","best rec: 0.5273613396363939\n","best f1: 0.5554126156023513\n","\n","Final Results:\n","Accuracy: 0.7311827956989247\n","Precision: 0.6521739130406428\n","Recall: 0.4687499999985351\n","F1 score: 0.5454545454525619\n"]}],"source":["# Dataset 2\n","# Train test split\n","split_ind = int(0.8*len(X2))\n","X_train = X2[:split_ind]\n","y_train = y2[:split_ind]\n","\n","X_test = X2[split_ind:]\n","y_test = y2[split_ind:]\n","\n","# Optimize parameters using X_train\n","print('Grid Search Results:')\n","l2, g2 = SVM_test_params(X_train, y_train)\n","\n","# Train best model and evaluate\n","model2 = rbf_SVM(C = l2, gamma = g2)\n","model2.fit(X_train, y_train)\n","y_pred = model2.predict(X_test)\n","\n","print()\n","acc, prec, rec, f1 = eval_predictions(y_test, y_pred)\n","print(\"Final Results:\")\n","print(f'Accuracy: {acc}')\n","print(f'Precision: {prec}')\n","print(f'Recall: {rec}')\n","print(f'F1 score: {f1}')"]},{"cell_type":"markdown","source":["# kNN"],"metadata":{"id":"GSEqpduZZW9W"}},{"cell_type":"markdown","source":["### Dataset1"],"metadata":{"id":"VZ62iUDAJRtW"}},{"cell_type":"code","source":["# instantiate the KNNModel\n","knn_model = KNNModel()\n","\n","#range of neighbor values to try\n","num_neighbors_values = [1, 3, 5, 7, 9]\n","\n","# Perform 10-fold cross-validation\n","print(\"----- Dataset 1 -----\")\n","results = cross_val_10fold1(knn_model, X1, y1, num_neighbors_values)\n","\n","best_value = np.argmax(results['f1_score'])\n","print(f'Best Performing Configuration:')\n","print(f'Num Neighbors: {results[\"num_neighbors\"][best_value]}')\n","print(f'Accuracy: {results[\"accuracy\"][best_value]:.4}')\n","print(f'Precision: {results[\"precision\"][best_value]:.4}')\n","print(f'Recall: {results[\"recall\"][best_value]:.4}')\n","print(f'F1-Score: {results[\"f1_score\"][best_value]:.4}')\n","\n","# Instantiate the KNNModel\n","knn_model = KNNModel()\n","\n","# Perform 10-fold cross-validation\n","print(\"----- Dataset 2 -----\")\n","results = cross_val_10fold1(knn_model, X2, y2, num_neighbors_values)\n","\n","best_value = np.argmax(results['f1_score'])\n","print(f'Best Performing Configuration:')\n","print(f'Num Neighbors: {results[\"num_neighbors\"][best_value]}')\n","print(f'Accuracy: {results[\"accuracy\"][best_value]:.4}')\n","print(f'Precision: {results[\"precision\"][best_value]:.4}')\n","print(f'Recall: {results[\"recall\"][best_value]:.4}')\n","print(f'F1-Score: {results[\"f1_score\"][best_value]:.4}')"],"metadata":{"id":"4pjOIZ_u7Miq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709835860907,"user_tz":300,"elapsed":31076,"user":{"displayName":"Jerry Xiao","userId":"01620358338097358872"}},"outputId":"1598e8a0-7d37-4748-e169-a56b606ba986"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["----- Dataset 1 -----\n","Best Performing Configuration:\n","Num Neighbors: 5\n","Accuracy: 0.9722\n","Precision: 0.9885\n","Recall: 0.9368\n","F1-Score: 0.9613\n","----- Dataset 2 -----\n","Best Performing Configuration:\n","Num Neighbors: 3\n","Accuracy: 0.6714\n","Precision: 0.5319\n","Recall: 0.4304\n","F1-Score: 0.4715\n"]}]},{"cell_type":"markdown","source":["# Decision Tree"],"metadata":{"id":"1rb3dmexZqpX"}},{"cell_type":"code","source":["# Assuming X1 and y1 are your dataset\n","# Split the data based on hyperparam tuning\n","split_ind = int(0.8 * len(X1))\n","X_train = X1[:split_ind]\n","y_train = y1[:split_ind]\n","\n","X_test = X1[split_ind:]\n","y_test = y1[split_ind:]\n","\n","# Train the DecisionTree model\n","dt_model = DecisionTree()\n","\n","# Perform cross-validation on the training set\n","cross_val_10fold2(dt_model, X_train, y_train)\n","\n","# Train the model on the full training set\n","dt_model.train(X_train, y_train)\n","\n","# Evaluate the final model using the testing set\n","y_pred = dt_model.predict(X_test)\n","y_pred_class = np.argmax(y_pred, axis=1)\n","\n","\n","# Print evaluation metrics\n","acc = calculate_accuracy(y_test, y_pred_class)\n","prec = precision(y_test, y_pred_class)\n","rec = recall(y_test, y_pred_class)\n","f1 = f1_score(y_test, y_pred_class)\n","\n","print(\"Final Results:\")\n","print(f'Accuracy: {acc}')\n","print(f'Precision: {prec}')\n","print(f'Recall: {rec}')\n","print(f'F1 score: {f1}')\n"],"metadata":{"id":"8ejXB2t_GVHF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709835867537,"user_tz":300,"elapsed":710,"user":{"displayName":"Jerry Xiao","userId":"01620358338097358872"}},"outputId":"3c4a1687-a85d-448c-9105-203824ec8441"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Final Results:\n","Accuracy: 0.9385964912280702\n","Precision: 0.9999999999971428\n","Recall: 0.8333333333313492\n","F1 score: 0.9090909090885477\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CSDS 335/Project1/code/decisiontree.py:187: RuntimeWarning: invalid value encountered in scalar divide\n","  return 2 * (prec * rec) / (prec + rec)\n"]}]},{"cell_type":"code","source":["# Assuming X2 and y2 are your dataset\n","split_ind = int(0.8 * len(X1))\n","X_train = X2[:split_ind]\n","y_train = y2[:split_ind]\n","\n","X_test = X2[split_ind:]\n","y_test = y2[split_ind:]\n","\n","# Train the DecisionTree model\n","dt_model = DecisionTree()\n","\n","# Perform cross-validation on the training set\n","cross_val_10fold2(dt_model, X_train, y_train)\n","\n","# Train the model on the full training set\n","dt_model.train(X_train, y_train)\n","\n","# Evaluate the final model using the testing set\n","y_pred = dt_model.predict(X_test)\n","y_pred_class = np.argmax(y_pred, axis=1)\n","\n","\n","# Print evaluation metrics\n","acc = calculate_accuracy(y_test, y_pred_class)\n","prec = precision(y_test, y_pred_class)\n","rec = recall(y_test, y_pred_class)\n","f1 = f1_score(y_test, y_pred_class)\n","\n","print(\"Final Results:\")\n","print(f'Accuracy: {acc}')\n","print(f'Precision: {prec}')\n","print(f'Recall: {rec}')\n","print(f'F1 score: {f1}')\n"],"metadata":{"id":"4UCPLA4TZx8O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709835867537,"user_tz":300,"elapsed":14,"user":{"displayName":"Jerry Xiao","userId":"01620358338097358872"}},"outputId":"5b3fef26-3347-4754-8222-3339d5de42fe"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Final Results:\n","Accuracy: 0.5714285714285714\n","Precision: 0.3333333333222222\n","Recall: 0.499999999975\n","F1 score: 0.399999999984\n"]}]},{"cell_type":"markdown","source":["# AdaBoost"],"metadata":{"id":"UgOPGiHoaAff"}},{"cell_type":"code","source":["#DecisionTREE\n","import math\n","import numpy as np\n","from collections import Counter\n","\n","class TreeNode():\n","  def __init__(self, dataset, feature_index, threshold, prediction_probs, info_gain) -> None:\n","    self.data = dataset\n","    self.feature_index = feature_index\n","    self.threshold = threshold\n","    self.prediction_probs = prediction_probs\n","    self.info_gain = info_gain\n","    self.left = None\n","    self.right = None\n","\n","class DecisionTree():\n","\n","  def __init__(self, max_depth=6, min_samples_split=1, min_info_gain=0.0, num_features_split=None, adaboost_weight=None) -> None:\n","    self.max_depth = max_depth\n","    self.min_samples_split = min_samples_split\n","    self.min_info_gain = min_info_gain\n","    self.num_features_split = num_features_split\n","    self.adaboost_weight = adaboost_weight\n","    self.tree = None\n","\n","\n","  #using entropy class formula\n","  def entropy(self, class_probs: list) -> float:\n","    return sum([-p * np.log2(p) for p in class_probs if p > 0])\n","\n","  def class_probs(self, targets: list) -> list:\n","    total = len(targets)\n","    return [target_count/total for target_count in Counter(targets).values()]\n","\n","  def data_entropy(self, targets: list) -> float:\n","    return self.entropy(self.class_probs(targets))\n","\n","  def partition_entropy(self, subsets: list) -> float:\n","    total = sum([len(subset) for subset in subsets])\n","    return sum([self.data_entropy(subset) * (len(subset) / total) for subset in subsets])\n","\n","  def split(self, dataset: np.array, feature_index: int, threshold: float) -> tuple:\n","    #all rows that are less than threshold\n","    below_threshold_group = dataset[:, feature_index] < threshold\n","    group1 = dataset[below_threshold_group]\n","    group2 = dataset[~below_threshold_group]\n","    return group1, group2\n","\n","  def target_probs(self, dataset: np.array) -> np.array:\n","    target_values = dataset[:, -1]\n","    total_target_values = len(target_values)\n","    target_probs = np.zeros(len(self.target_values), dtype=float)\n","\n","    for i, target_val in enumerate(self.target_values):\n","      target_index = np.where(target_values == i)[0]\n","      if len(target_index) > 0:\n","        target_probs[i] = len(target_index) / total_target_values\n","\n","    return target_probs\n","\n","  def best_split(self, dataset: np.array) -> tuple:\n","    min_entropy = math.inf\n","    min_entropy_feature_index = None\n","    min_entropy_threshold = None\n","\n","    for i in range(dataset.shape[1]-1):\n","      threshold = np.median(dataset[:, i])\n","      subtree1, subtree2 = self.split(dataset, i, threshold)\n","      split_entropy = self.partition_entropy([subtree1[:, -1], subtree2[:, -1]])\n","      #finding split with lowest entropy\n","      if split_entropy < min_entropy:\n","        min_entropy = split_entropy\n","        min_entropy_feature_index = i\n","        min_entropy_threshold = threshold\n","        subtree1_min, subtree2_min = subtree1, subtree2\n","\n","    return subtree1_min, subtree2_min, min_entropy_feature_index, min_entropy_threshold, min_entropy\n","\n","  def build_tree(self, dataset: np.array, curr_depth: int) -> TreeNode:\n","    if curr_depth >= self.max_depth:\n","      return None\n","\n","    subtree1, subtree2, split_feature_index, split_threshold, split_entropy = self.best_split(dataset)\n","\n","    target_probs = self.target_probs(dataset)\n","\n","    node_entropy = self.entropy(target_probs)\n","    info_gain = node_entropy - split_entropy\n","\n","    node = TreeNode(dataset, split_feature_index, split_threshold, target_probs, info_gain)\n","\n","    if(self.min_samples_split > subtree1.shape[0] or self.min_samples_split > subtree2.shape[0]):\n","      return node\n","\n","    elif info_gain < self.min_info_gain:\n","      return node\n","\n","    curr_depth = curr_depth + 1\n","    #continue recursively until one of return conditions is met\n","    node.left = self.build_tree(subtree1, curr_depth)\n","    node.right = self.build_tree(subtree2, curr_depth)\n","\n","    return node\n","  def predict_one_sample(self, X: np.array) -> np.array:\n","    node = self.tree\n","\n","    while node:\n","        if node.left is None and node.right is None:  # Check if the node is a leaf\n","            return node.prediction_probs\n","        else:\n","            if X[node.feature_index] < node.threshold:\n","                node = node.left\n","            else:\n","                node = node.right\n","\n","    # Handle the case where no leaf node is reached\n","    return None  # Or raise an exception if needed\n","\n","  def train(self, X_train: np.array, Y_train: np.array) -> None:\n","    self.target_values = np.unique(Y_train)\n","    train_data = np.concatenate((X_train, np.reshape(Y_train, (-1, 1))), axis=1)\n","\n","    self.tree = self.build_tree(dataset=train_data, curr_depth=0)\n","\n","\n","  def predict_probs(self, X_set: np.array) -> np.array:\n","    pred_prob = np.apply_along_axis(self.predict_one_sample, 1, X_set)\n","\n","    return pred_prob\n","\n","  def predict(self, X_set: np.array) -> np.array:\n","    predictions = []\n","    for sample in X_set:\n","        prediction = self.predict_one_sample(sample)\n","        predictions.append(prediction)\n","    return np.array(predictions)"],"metadata":{"id":"zWLKasrCG6c4","executionInfo":{"status":"ok","timestamp":1709835867537,"user_tz":300,"elapsed":8,"user":{"displayName":"Jerry Xiao","userId":"01620358338097358872"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from collections import Counter\n","\n","class AdaBoost():\n","    def __init__(self, num_base_learners=10):\n","        self.num_base_learners = num_base_learners\n","        self.base_learners = []\n","        self.base_learner_weights = []\n","\n","    def calc_adaboost_weight(self, base_learner, X, y):\n","        prediction = base_learner.predict(X)\n","        prediction = np.argmax(prediction, axis=1)\n","        err = 1 - np.mean(prediction == y)\n","        return 0.5 * np.log((1 - err) / max(err, 1e-10))\n","\n","    def train(self, X_train, y_train):\n","        n_samples = X_train.shape[0]\n","        weights = np.ones(n_samples) / n_samples\n","\n","        for _ in range(self.num_base_learners):\n","            base_learner = DecisionTree(max_depth=6)\n","            base_learner.train(X_train, y_train)\n","            adaboost_weight = self.calc_adaboost_weight(base_learner, X_train, y_train)\n","            self.base_learners.append(base_learner)\n","            self.base_learner_weights.append(adaboost_weight)\n","\n","            predictions = base_learner.predict(X_train)\n","            predicted_labels = np.argmax(predictions, axis=1)  # Convert probabilities to class labels\n","            err = np.mean(predicted_labels != y_train)\n","            beta = err / (1 - err)\n","            errors = (predicted_labels != y_train)\n","            weights *= np.exp(beta * errors)\n","            weights /= np.sum(weights)\n","\n","\n","    def predict(self, X):\n","        pred_scores = np.zeros((len(X), len(self.base_learners[0].target_values)))\n","\n","        for i, base_learner in enumerate(self.base_learners):\n","            pred_probs = base_learner.predict_probs(X)\n","            pred_scores += pred_probs * self.base_learner_weights[i]\n","\n","        return np.argmax(pred_scores, axis=1)\n","\n"],"metadata":{"id":"m8RFL7NSD6A0","executionInfo":{"status":"ok","timestamp":1709835867538,"user_tz":300,"elapsed":8,"user":{"displayName":"Jerry Xiao","userId":"01620358338097358872"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["#Dataset 1\n","adaboost = AdaBoost()\n","\n","adaboost.train(X1, y1)\n","\n","print('For Dataset1:')\n","_, _, _, _ = cross_val_10fold3(adaboost, X1, y1)\n","print()\n","\n","#Dataset 2\n","adaboost2 = AdaBoost()\n","\n","adaboost2.train(X2, y2)\n","\n","print('For Dataset2:')\n","_, _, _, _ = cross_val_10fold3(adaboost2, X2, y2)"],"metadata":{"id":"KMhKtRfsaC_X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709835869512,"user_tz":300,"elapsed":1981,"user":{"displayName":"Jerry Xiao","userId":"01620358338097358872"}},"outputId":"4bb834f7-4766-4dcd-a82c-a3438a9dc779"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["For Dataset1:\n","----- Over 10 folds -----\n","Accuracy: 0.9525\n","Precision: 0.9688\n","Recall: 0.904\n","F1-Score: 0.9339\n","\n","For Dataset2:\n","----- Over 10 folds -----\n","Accuracy: 0.7573\n","Precision: 0.6929\n","Recall: 0.5245\n","F1-Score: 0.5865\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"FhCY8HfjJeX_","executionInfo":{"status":"ok","timestamp":1709835869513,"user_tz":300,"elapsed":8,"user":{"displayName":"Jerry Xiao","userId":"01620358338097358872"}}},"execution_count":14,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1fkalJUzXqK5q1Jb-NTCkm3Fce54h3CwG","timestamp":1709832144513}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}